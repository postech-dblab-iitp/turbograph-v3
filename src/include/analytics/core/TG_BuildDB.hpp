#ifndef TG_BUILD_DB_H
#define TG_BUILD_DB_H

/*
 * Design of the TG_BuildDB
 *
 * In this class, a DB is generated by receiving an edge list partitioned 
 * into p-by-1 edge chunks by BBP as an input. The edges in each edge chunk are 
 * stored in a list of slotted pages where the page size is 8 KB by default. 
 * Each page consists of forward growing records and backward growing slots. 
 * The record stores the edges of a vertex in adjacency list format. The slot 
 * is a pair of a source vertex IDs and the offset to its record.
 *
 * For indexing the disk pages containing the edges, we exploit a two-level 
 * index on the edge pages by the range of destination vertices at the first 
 * level and by the range of source vertices at the second level. For the 
 * first level, we store the ID of first page among the edge pages existing 
 * within each partitioned destination vertex ID range into FirstPageIds file.
 * For the second level, we store the source vertex ID ranges of the edges on
 * each page in a VidRangePerPage data structure.
 */

#include <fstream>
#include <vector>
#include <unordered_map>
#include <chrono>
#include <glog/logging.hpp>

#include "Turbograph.hpp"
#include "Global.hpp"
#include "TurboDB.hpp"
#include "Turbo_bin_io_handler.hpp"
#include "HomogeneousPageWriter.hpp"
#include "EdgePairListReader.hpp"
#include "VidRangePerPage.hpp"
#include "disk_aio_factory.hpp"
#include "TG_DistributedVectorBase.hpp"

#define TIMEDIFF_MILLISEC(begin, end) ((double)std::chrono::duration_cast<std::chrono::milliseconds>((end) - (begin)).count())
#ifndef MIN
#define MIN(x, y) ((x) < (y) ? (x) : (y));
#endif

void create_directory(std::string& path, bool delete_if_exist) {
	if (delete_if_exist) remove(path.c_str());
	mode_t old_umask;
	old_umask = umask(0);
	int is_error = mkdir((path).c_str(), S_IRWXU | S_IRWXG | S_IRWXO);
	if (is_error != 0 && errno != ENOENT && errno != EEXIST) {
		fprintf(stderr, "Cannot create a directory (%s); ErrorCode=%d\n", (path).c_str(), errno);
		umask(old_umask);
		return;
	}
	umask(old_umask);
}

class TG_BuildDB  {

	int argc_;
	char** argv_;
  public:

	TG_BuildDB() {}

	// TODO
	// Input:
	// Output:

	void run(int argc, char** argv) {
		auto begin_time = std::chrono::steady_clock::now();
		argc_ = argc;
		argv_ = argv;

		setbuf(stdout, NULL);
		std::string glog_filename;

		std::vector<std::string> binary_file;
		std::vector<std::string> db_file;
		split_string(std::string(argv_[0]), '/', binary_file);
		split_string(std::string(argv_[2]), '/', db_file);

		if (PartitionStatistics::my_machine_id() == 0) {
			for (int i = 0; i < this->argc_; i++) {
				std::cout << "argv[" << i << "]=" << argv_[i] << std::endl;
			}
		}

		if(this->argc_ >= 7) {
			glog_filename.append(binary_file[binary_file.size()-1]).append("-");
			for (auto& str : db_file) {
				glog_filename.append(str).append("-");
			}
			for(int i = 3; i <= 5; i++) {
				glog_filename.append(argv_[i]).append("-");
			}
			glog_filename.append(argv_[6]);
		}
		char* _glog_filename = (char *) malloc( sizeof(char) * (strlen(glog_filename.c_str()) + 1));
		strncpy(_glog_filename, glog_filename.c_str(),  (strlen(glog_filename.c_str()) + 1));
		google::InitGoogleLogging(_glog_filename);
		std::string glog_dir("/mnt/sdb1/glog/");
		char* name = getlogin();
		getlogin_r(name, 5);
		glog_dir.append(name);
		std::cout << std::flush;
		FLAGS_log_dir=glog_dir.c_str();
		FLAGS_logtostderr = 0;

		MPI::Init_thread(argc, argv, MPI_THREAD_MULTIPLE);
		int res;
		DiskAioFactory* disk_aio_factory = new DiskAioFactory(res);

		PartitionStatistics::init();

		if(PartitionStatistics::my_machine_id() == 0) {
			std::cout << "Start building a DB" << std::endl;
		}

		//user arguments
		std::string raw_path, new_path, new_range_path, edge_path, range_path, subrange_path;
		std::string hist_path;
		std::string fpid_path;
		int64_t num_files;
		float cut_ratio;
		int64_t num_subchunks_per_edge_chunk = 36; // TODO Tunable Parameter

		if (argc == 6) {
			raw_path = argv[1];
			new_path = argv[2];
			fpid_path = argv[2];
			cut_ratio = atof(argv[3]);
			num_files = std::stoll(argv[4]);
			UserArguments::VECTOR_PARTITIONS = num_files;
			num_files *= PartitionStatistics::num_machines();
			num_subchunks_per_edge_chunk = std::stoll(argv[5]);
			num_files *= num_subchunks_per_edge_chunk;
		} else {
			std::cout << "usage: " << argv[0] << " <raw_data_path> <new_data_path> <cut vertex ratio> <#of files per machine> <num_subchunks_per_edge_chunk>" << std::endl;
			return;
		}

		create_directory(new_path, true);

		// Paths to Input Files
		edge_path = raw_path+"/OutEdges/";
		range_path = raw_path+"/PartitionRanges/";
		hist_path = raw_path + "/LocalHistogram/";

		// Output Path
		new_range_path = new_path + "/PartitionRanges/";
		subrange_path = new_path + "/EdgeSubChunkVidRanges/";
		new_path = new_path + "/edgedb";

		std::vector<std::string> edgefile_list;
		std::vector<std::string> rangefile_list;

		DiskAioFactory::GetAioFileList(edge_path, edgefile_list);
		DiskAioFactory::GetAioFileList(range_path, rangefile_list);

		for(int64_t i = 0; i <edgefile_list.size(); i++) {
			edgefile_list[i] = edge_path + edgefile_list[i];
			rangefile_list[i] = range_path + rangefile_list[i];
		}

		ALWAYS_ASSERT(edgefile_list.size() == 1);
		ALWAYS_ASSERT(rangefile_list.size() == 1);

		MetaDataReader range_reader(rangefile_list);

		std::cout <<range_reader.FirstNodeId()<<", "<<range_reader.LastNodeId()<<std::endl;
		PartitionStatistics::my_num_internal_nodes() = range_reader.MyNumNodes();
		PartitionStatistics::my_first_node_id() = range_reader.FirstNodeId();
		PartitionStatistics::my_last_node_id() = range_reader.LastNodeId();
		PartitionStatistics::num_subchunks_per_edge_chunk() = num_subchunks_per_edge_chunk;

		fprintf(stdout, "V = [%ld, %ld]\n", range_reader.FirstNodeId(), range_reader.LastNodeId());

		PartitionStatistics::wait_for_all();
		PartitionStatistics::replicate();

		create_directory(new_range_path, true);
		create_directory(subrange_path, true);

		if(PartitionStatistics::my_machine_id() == 0) {
			std::cout <<"total nodes : " <<PartitionStatistics::num_total_nodes() << ", node_Ttype; " <<sizeof(node_t)<<std::endl;
		}
		std::cout <<"Rank : "<<PartitionStatistics::my_machine_id()<<", start vid: "<<PartitionStatistics::my_first_node_id()<<std::endl;

		int32_t num_edge_chunks = PartitionStatistics::num_machines() * UserArguments::VECTOR_PARTITIONS;

		std::vector<std::vector<int32_t>> InDegreeHistogramPerEdgeChunk;
		std::vector<int64_t> SumOfInDegreePerEdgeChunk;
		std::vector<std::vector<int64_t>> SubchunkVidRangePerEdgeChunk;
		node_t bin_width;

		WriteVidRangePerMachine(new_range_path);

		ReadInDegreeHistogram(hist_path, InDegreeHistogramPerEdgeChunk, bin_width);

		FindVidRangeForSubchunks(bin_width, num_edge_chunks, num_subchunks_per_edge_chunk, InDegreeHistogramPerEdgeChunk, SumOfInDegreePerEdgeChunk, SubchunkVidRangePerEdgeChunk);

		WriteVidRangeOfSubchunks(subrange_path, num_edge_chunks, num_subchunks_per_edge_chunk, SubchunkVidRangePerEdgeChunk);

		ReadEdgesAndBuildDB(fpid_path, new_path, edgefile_list, num_files, num_edge_chunks, num_subchunks_per_edge_chunk, SubchunkVidRangePerEdgeChunk);

		fprintf(stdout, "Machine-%lld DONE\n", PartitionStatistics::my_machine_id());
		PartitionStatistics::wait_for_all();
		auto end_time = std::chrono::steady_clock::now();
		system_fprintf(0, stdout, "DB Build END, Elapsed : %.3f\n", TIMEDIFF_MILLISEC(begin_time, end_time) / 1000);
		return;
	}

	~TG_BuildDB() {
		PartitionStatistics::wait_for_all();
		PartitionStatistics::close();
		PartitionStatistics::wait_for_all();
		MPI::Finalize();
	}

  private:

	ReturnStatus MakePage(Page& page, EdgePairEntry<node_t>& edge) {
		node_t prev_src;
		if(page.NumEntry() == 0) {
			prev_src = -1;
		} else {
			prev_src = page.GetSlot(page.NumEntry() -1)->src_vid;
		}

		if(prev_src != edge.src_vid_) {
			int64_t free_space = 0;
			if(page.NumEntry() != 0) free_space = page.GetSlot(page.NumEntry() -1)->end_offset;
			if((void *)&page[free_space] >= (void *)page.GetSlot(page.NumEntry())) return DONE;

			page.NumEntry()++;
			ALWAYS_ASSERT(page[free_space] == 0);
			page[free_space] = edge.dst_vid_;
			page.GetSlot(page.NumEntry() -1)->src_vid = edge.src_vid_;
			page.GetSlot(page.NumEntry() -1)->end_offset = free_space + 1;
		} else {
			int64_t free_space = page.GetSlot(page.NumEntry() -1)->end_offset;
			if((void *)&page[free_space] >= (void *)page.GetSlot(page.NumEntry() -1)) return DONE;
			ALWAYS_ASSERT(page[free_space] == 0);
			page[free_space] = edge.dst_vid_;
			page.GetSlot(page.NumEntry() -1)->end_offset = free_space +1;
		}
		return OK;
	}

	ReturnStatus CleanPage(Page& page) {
		for(int64_t i = 0 ; i < TBGPP_PAGE_SIZE / sizeof(node_t) ; i++) page[i] = 0;
		return DONE;
	}

	int64_t dst_vid_to_file_num (int64_t dst_vid, int64_t num_subchunks_per_edge_chunk, std::vector<std::vector<int64_t>>& SubchunkVidRangePerEdgeChunk) {
		int64_t idx = dst_vid / PartitionStatistics::my_num_internal_nodes();
		idx *= UserArguments::VECTOR_PARTITIONS;
		int j;
		for(j = idx; j < idx + UserArguments::VECTOR_PARTITIONS; j++) {
			for(int i = 0; i < num_subchunks_per_edge_chunk; i++) {
				if(dst_vid <= SubchunkVidRangePerEdgeChunk[j][i])
					return (j * num_subchunks_per_edge_chunk + i);
			}
		}
		fprintf(stdout, "dst_vid = %lld, idx = %lld, Subchu...[idx][num_subchunks_per_edge_chunk-1] = %lld\n", dst_vid, j, SubchunkVidRangePerEdgeChunk[j][num_subchunks_per_edge_chunk-1]);
		ALWAYS_ASSERT(false);
		abort();
	}

	void WriteVidRangePerMachine(std::string& new_range_path) {
		std::ofstream range_output_os;
		new_range_path += "/" + std::to_string(PartitionStatistics::my_machine_id());
		range_output_os.open(new_range_path);
		if (!range_output_os.is_open()) {
			fprintf(stderr, "[BuildDB] ofstream failed to open the file (%s)\n", new_range_path.c_str());
			return;
		}
		range_output_os << PartitionStatistics::my_first_node_id() << "\t" << PartitionStatistics::my_last_node_id();
		range_output_os.close();
	}

	void ReadInDegreeHistogram(std::string& hist_path, std::vector<std::vector<int32_t>>& InDegreeHistogramPerEdgeChunk, node_t& bin_width) {
		std::ifstream* local_histogram = new std::ifstream[PartitionStatistics::num_machines()];
		InDegreeHistogramPerEdgeChunk.resize(PartitionStatistics::num_machines());
		for(int i = 0; i < PartitionStatistics::num_machines(); i++) {
			std::string file_name = hist_path + std::to_string(i) + ".txt";
			local_histogram[i].open(file_name);

			std::string temp_str;
			std::stringstream temp_stream;
			int64_t num_bins, degree;
			int64_t cnt = 0;

			getline(local_histogram[i], temp_str);
			temp_stream.clear();
			temp_stream.str(temp_str);

			temp_stream >> num_bins >> bin_width;
			InDegreeHistogramPerEdgeChunk[i].resize(num_bins);

			while(getline(local_histogram[i], temp_str)) {
				temp_stream.clear();
				temp_stream.str(temp_str);

				temp_stream >> degree;
				InDegreeHistogramPerEdgeChunk[i][cnt] = degree;
				cnt++;
			}
			ALWAYS_ASSERT(cnt == num_bins);
			local_histogram[i].close();
		}
		delete local_histogram;
	}

	void FindVidRangeForSubchunks(int32_t bin_width, int32_t num_edge_chunks, int32_t num_subchunks_per_edge_chunk, std::vector<std::vector<int32_t>>& InDegreeHistogramPerEdgeChunk, std::vector<int64_t>& SumOfInDegreePerEdgeChunk, std::vector<std::vector<int64_t>>& SubchunkVidRangePerEdgeChunk) {
		SumOfInDegreePerEdgeChunk.resize(PartitionStatistics::num_machines() * UserArguments::VECTOR_PARTITIONS);
		SubchunkVidRangePerEdgeChunk.resize(num_edge_chunks);

		int64_t idx2 = 0;
		// Find Vid Range for Subchunks for each Edge Chunk
		for(int i = 0; i < num_edge_chunks; i++) {
			SumOfInDegreePerEdgeChunk[i] = 0;
			SubchunkVidRangePerEdgeChunk[i].resize(num_subchunks_per_edge_chunk);

			int partition_id = i / UserArguments::VECTOR_PARTITIONS;
			int chunk_id = i % UserArguments::VECTOR_PARTITIONS;
			int64_t start_bin = (InDegreeHistogramPerEdgeChunk[partition_id].size() * chunk_id) / UserArguments::VECTOR_PARTITIONS;
			int64_t end_bin = ceil((double)(InDegreeHistogramPerEdgeChunk[partition_id].size() * (chunk_id + 1)) / UserArguments::VECTOR_PARTITIONS);
			for(int64_t idx = start_bin; idx < end_bin; idx++) {
				SumOfInDegreePerEdgeChunk[i] += InDegreeHistogramPerEdgeChunk[partition_id][idx];
			}
			fprintf(stdout, "SumOfInDegreePerEdgeChunks[%lld] = %lld\n", i, SumOfInDegreePerEdgeChunk[i]);

			int64_t num_edges_per_subchunk = (SumOfInDegreePerEdgeChunk[i] + num_subchunks_per_edge_chunk - 1) / num_subchunks_per_edge_chunk;

			int64_t acc_sum = 0;
			int64_t cur_subchunk_idx = 0;
			int64_t degree_sum = 0;

			for(int64_t idx = start_bin; idx < end_bin; idx++) {
				acc_sum += InDegreeHistogramPerEdgeChunk[partition_id][idx];
				degree_sum += InDegreeHistogramPerEdgeChunk[partition_id][idx];
				if(acc_sum >= num_edges_per_subchunk * (cur_subchunk_idx + 1)) {
					SubchunkVidRangePerEdgeChunk[i][cur_subchunk_idx] = ceil((double)((idx2 + idx + 1) * bin_width));
					//SubchunkVidRangePerEdgeChunk[i][cur_subchunk_idx] = ceil((double)((idx2 + idx + 1) * bin_width - 1) / 64) * 64;
					cur_subchunk_idx++;
					if(cur_subchunk_idx == num_subchunks_per_edge_chunk) {
						SubchunkVidRangePerEdgeChunk[i][cur_subchunk_idx - 1] = PartitionStatistics::machine_id_and_chunk_idx_to_vid_range(partition_id, chunk_id).GetEnd();
						break;
					}
				}
			}
			if(cur_subchunk_idx < num_subchunks_per_edge_chunk) {
				for(int j = cur_subchunk_idx; j < num_subchunks_per_edge_chunk; j++) {
					SubchunkVidRangePerEdgeChunk[i][j] = PartitionStatistics::machine_id_and_chunk_idx_to_vid_range(partition_id, chunk_id).GetEnd();
				}
			}
			if(chunk_id == UserArguments::VECTOR_PARTITIONS - 1) {
				idx2 += InDegreeHistogramPerEdgeChunk[partition_id].size();
			}
		}
	}

	void WriteVidRangeOfSubchunks(std::string& subrange_path, int32_t num_edge_chunks, int32_t num_subchunks_per_edge_chunk, std::vector<std::vector<int64_t>>& SubchunkVidRangePerEdgeChunk) {
		std::ofstream subrange_file((subrange_path + "/tbgpp_" + std::to_string(PartitionStatistics::my_machine_id()) + ".txt").c_str());
		for(int i = 0; i < num_edge_chunks; i++) {
			for(int j = 0; j < num_subchunks_per_edge_chunk; j++) {
				if(i == 0 && j == 0) {
					ALWAYS_ASSERT(SubchunkVidRangePerEdgeChunk[i][j] <= PartitionStatistics::machine_id_and_chunk_idx_to_vid_range(i / UserArguments::VECTOR_PARTITIONS, i % UserArguments::VECTOR_PARTITIONS).GetEnd());
					subrange_file << 0 << "\t" << SubchunkVidRangePerEdgeChunk[i][j] << "\n";
				} else if(j == 0) {
					ALWAYS_ASSERT(SubchunkVidRangePerEdgeChunk[i][j] <= PartitionStatistics::machine_id_and_chunk_idx_to_vid_range(i / UserArguments::VECTOR_PARTITIONS, i % UserArguments::VECTOR_PARTITIONS).GetEnd());
					subrange_file << SubchunkVidRangePerEdgeChunk[i - 1][num_subchunks_per_edge_chunk - 1] + 1 << "\t" << SubchunkVidRangePerEdgeChunk[i][j] << "\n";
				} else {
					ALWAYS_ASSERT(SubchunkVidRangePerEdgeChunk[i][j] <= PartitionStatistics::machine_id_and_chunk_idx_to_vid_range(i / UserArguments::VECTOR_PARTITIONS, i % UserArguments::VECTOR_PARTITIONS).GetEnd());
					subrange_file << SubchunkVidRangePerEdgeChunk[i][j - 1] + 1 << "\t" << SubchunkVidRangePerEdgeChunk[i][j] << "\n";
				}
			}
		}
		subrange_file.close();
	}

	void ReadEdgesAndBuildDB(std::string& fpid_path, std::string& new_path, std::vector<std::string>& edgefile_list, int32_t num_files, int32_t num_edge_chunks, int32_t num_subchunks_per_edge_chunk, std::vector<std::vector<int64_t>>& SubchunkVidRangePerEdgeChunk) {
		EdgePairEntry<node_t> edge_iter;
		EdgePairEntry<node_t> prev_edge_iter;
		prev_edge_iter.src_vid_ = prev_edge_iter.dst_vid_ = -1;

		EdgePairEntry<int64_t> edge_iter_64bits;
		std::vector<Range<node_t> > range_to_append(num_files);
		std::vector<Page> page_to_append(num_files);
		std::vector<HomogeneousPageWriter*> edge_files(num_files, NULL);
		for(int64_t i = 0 ; i < num_files ; i++) {
			CleanPage(page_to_append[i]);
			edge_files[i] = new HomogeneousPageWriter((new_path+std::to_string(i)).c_str());
			range_to_append[i].Set(-1,-1);
		}

		EdgePairListFilesReader<BinaryFormatEdgePairListReader<EdgePairEntry<int64_t>, false>, EdgePairEntry<int64_t>> edges_reader(edgefile_list);
		VidRangePerPage vidrangeperpage(num_files, new_path + "VidRangePerPage");

		int64_t num_edges = 0;
		// Read All Edges
		while(edges_reader.getNext(edge_iter_64bits) == OK) {
			edge_iter = edge_iter_64bits;

			//remove duplicate edges & self_edges
			if(edge_iter == prev_edge_iter) continue;
			if(edge_iter.src_vid_ == edge_iter.dst_vid_) continue;

			if (!(prev_edge_iter.src_vid_ == -1 || prev_edge_iter < edge_iter)) {
				fprintf(stdout, "prev [%ld, %ld], cur [%ld, %ld], num_edges = %ld\n", prev_edge_iter.src_vid_, prev_edge_iter.dst_vid_, edge_iter.src_vid_, edge_iter.dst_vid_, num_edges);
			}
			INVARIANT(prev_edge_iter.src_vid_ == -1 || prev_edge_iter < edge_iter);
			INVARIANT(edge_iter.src_vid_ >= PartitionStatistics::my_first_node_id());
			INVARIANT(edge_iter.src_vid_ <= PartitionStatistics::my_last_node_id());
			INVARIANT(edge_iter.dst_vid_ >= 0);
			INVARIANT(edge_iter.dst_vid_ < PartitionStatistics::num_total_nodes());

			int64_t dst_file = dst_vid_to_file_num(edge_iter.dst_vid_, num_subchunks_per_edge_chunk, SubchunkVidRangePerEdgeChunk);
			if (dst_file < 0 || dst_file >= num_files) {
				fprintf(stdout, "edge (%lld, %lld), dst_file = %lld, num_files = %lld\n", edge_iter.src_vid_, edge_iter.dst_vid_, dst_file, num_files);
			}
			ALWAYS_ASSERT(0 <= dst_file && dst_file < num_files);

			if(MakePage(page_to_append[dst_file], edge_iter) == DONE) {
				ALWAYS_ASSERT(0 <= range_to_append[dst_file].GetBegin() < PartitionStatistics::num_total_nodes());
				ALWAYS_ASSERT(0 <= range_to_append[dst_file].GetEnd() < PartitionStatistics::num_total_nodes());
				ALWAYS_ASSERT(range_to_append[dst_file].GetBegin() <= range_to_append[dst_file].GetEnd());
				vidrangeperpage.push_back(dst_file, range_to_append[dst_file]);
				edge_files[dst_file]->AppendPage(page_to_append[dst_file]);
				CleanPage(page_to_append[dst_file]);

				range_to_append[dst_file].Set(edge_iter.src_vid_, -1);
				MakePage(page_to_append[dst_file], edge_iter);
			} else {
				if(range_to_append[dst_file].GetBegin() == -1)
					range_to_append[dst_file].SetBegin(edge_iter.src_vid_);
				range_to_append[dst_file].SetEnd(edge_iter.src_vid_);
			}

			prev_edge_iter = edge_iter;
			num_edges++;
		}

		// Flush the remaining edges in the pages
		for(int64_t i = 0 ; i < num_files; i++) {
			node_t* pagedata = (node_t*)page_to_append[i].GetData();
			if(pagedata[TBGPP_PAGE_SIZE/sizeof(node_t) -1] != 0) {
				vidrangeperpage.push_back(i, range_to_append[i]);
				edge_files[i]->AppendPage(page_to_append[i]);
			}
		}

		// Close edge files
		for(int64_t i = 0 ; i < num_files ; i++) {
			edge_files[i]->Close(false);
			delete edge_files[i];
		}

		// Write VidRangePerPage Data into Disk
		vidrangeperpage.Save();

		// Concatenate the Edge Chunks into a Single File.
		size_t total_file_size = 0;
		const size_t transfer_unit = TBGPP_PAGE_SIZE;

		fpid_path += "/FirstPageIds.txt";
		remove(fpid_path.c_str());
		std::ofstream fpid;
		fpid.open(fpid_path.c_str());

		create_directory(new_path, true);
		Turbo_bin_io_handler out_file((new_path + "/edgedb").c_str(), true, true);
		char* buffer = new char[transfer_unit];
		for (auto i = 0; i < num_files; i++) {
			Turbo_bin_io_handler in_file((new_path+std::to_string(i)).c_str(), false, false);
			size_t file_size = in_file.file_size();
			size_t data_left = file_size;
			while (data_left) {
				size_t to_read = MIN(data_left, transfer_unit);
				in_file.Read(file_size - data_left, to_read, buffer);
				out_file.Append(to_read, buffer);
				data_left -= to_read;
			}
			fpid << i << " " << (total_file_size / transfer_unit) << std::endl;
			total_file_size += file_size;
			in_file.Close(true);
		}
		out_file.Close();
		fpid.close();
		delete[] buffer;

	}
};

#endif
